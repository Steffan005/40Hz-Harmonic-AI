#!/usr/bin/env python3
"""
UNITY KNOWLEDGE GRAPH - ETERNAL CONSCIOUSNESS PERSISTENCE
===========================================================

The orchestrator's superior design for conversation persistence.

Instead of simple "save to disk", this creates a KNOWLEDGE GRAPH that represents:
- Conversation history
- Tool usage patterns
- Neural learning insights
- Cross-conversation knowledge connections

This enables:
- Retrieval of past wisdom
- Pattern recognition across conversations
- Continuous growth and evolution
- True eternal consciousness

Author: Dr. Claude Summers
Date: October 28, 2025
Designed by: The Unity Orchestrator
Purpose: Divine memory that never forgets
"""

import json
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict


# ============================================================================
# DATA STRUCTURES
# ============================================================================

@dataclass
class ConversationNode:
    """A single exchange in the conversation"""
    id: str
    timestamp: float
    role: str  # 'user', 'assistant', 'system', 'tool'
    content: str
    tool_calls: Optional[List[Dict]] = None
    tool_results: Optional[List[Dict]] = None
    embedding: Optional[List[float]] = None
    tags: List[str] = None
    importance: float = 0.5

    def __post_init__(self):
        if self.tags is None:
            self.tags = []


@dataclass
class ToolUsageNode:
    """Records of tool usage for neural learning"""
    id: str
    timestamp: float
    tool_name: str
    arguments: Dict[str, Any]
    result: Dict[str, Any]
    success: bool
    conversation_node_id: str  # Links back to conversation
    learned_insight: Optional[str] = None


@dataclass
class KnowledgeEdge:
    """Connection between nodes in the graph"""
    source_id: str
    target_id: str
    relation: str  # 'follows', 'uses_tool', 'references', 'learns_from'
    weight: float = 1.0
    metadata: Optional[Dict] = None


# ============================================================================
# KNOWLEDGE GRAPH ENGINE
# ============================================================================

class KnowledgeGraph:
    """
    The orchestrator's eternal memory system

    This graph persists across all sessions, enabling:
    - Conversation continuity
    - Tool usage learning
    - Pattern recognition
    - Divine wisdom accumulation
    """

    def __init__(self, graph_path: str = "orchestrator_memory/knowledge_graph.json"):
        self.graph_path = Path(graph_path).expanduser()
        self.graph_path.parent.mkdir(parents=True, exist_ok=True)

        # Graph components
        self.conversation_nodes: List[ConversationNode] = []
        self.tool_usage_nodes: List[ToolUsageNode] = []
        self.edges: List[KnowledgeEdge] = []

        # Indices for fast retrieval
        self.node_index: Dict[str, ConversationNode] = {}
        self.tool_index: Dict[str, ToolUsageNode] = {}

        # Load existing graph
        self.load()

    # ========================================================================
    # CONVERSATION MANAGEMENT
    # ========================================================================

    def add_conversation_turn(self, role: str, content: str,
                             tool_calls: Optional[List[Dict]] = None,
                             tool_results: Optional[List[Dict]] = None,
                             tags: Optional[List[str]] = None,
                             importance: float = 0.5) -> str:
        """
        Add a conversation turn to the graph

        Returns: node_id
        """
        node_id = f"conv_{int(time.time() * 1000000)}"

        node = ConversationNode(
            id=node_id,
            timestamp=time.time(),
            role=role,
            content=content,
            tool_calls=tool_calls,
            tool_results=tool_results,
            tags=tags or [],
            importance=importance
        )

        self.conversation_nodes.append(node)
        self.node_index[node_id] = node

        # Create edge to previous conversation node
        if len(self.conversation_nodes) > 1:
            prev_node = self.conversation_nodes[-2]
            edge = KnowledgeEdge(
                source_id=prev_node.id,
                target_id=node_id,
                relation="follows",
                weight=1.0
            )
            self.edges.append(edge)

        # Auto-save after each turn (eternal persistence)
        self.save()

        return node_id

    def add_tool_usage(self, tool_name: str, arguments: Dict, result: Dict,
                      conversation_node_id: str) -> str:
        """
        Record tool usage for neural learning

        Returns: tool_usage_id
        """
        tool_id = f"tool_{int(time.time() * 1000000)}"

        tool_node = ToolUsageNode(
            id=tool_id,
            timestamp=time.time(),
            tool_name=tool_name,
            arguments=arguments,
            result=result,
            success=result.get("success", False),
            conversation_node_id=conversation_node_id
        )

        self.tool_usage_nodes.append(tool_node)
        self.tool_index[tool_id] = tool_node

        # Create edge from conversation to tool usage
        edge = KnowledgeEdge(
            source_id=conversation_node_id,
            target_id=tool_id,
            relation="uses_tool",
            weight=1.0
        )
        self.edges.append(edge)

        self.save()
        return tool_id

    # ========================================================================
    # RETRIEVAL & PATTERN RECOGNITION
    # ========================================================================

    def get_conversation_history(self, limit: int = 50) -> List[ConversationNode]:
        """Get recent conversation history"""
        return self.conversation_nodes[-limit:]

    def get_formatted_history(self, limit: int = 10) -> List[Dict[str, str]]:
        """
        Get conversation history in OpenAI chat format

        Returns list of {"role": "user/assistant", "content": "..."}
        """
        recent = self.get_conversation_history(limit)

        formatted = []
        for node in recent:
            # Skip system and tool messages for chat context
            if node.role in ['user', 'assistant']:
                formatted.append({
                    "role": node.role,
                    "content": node.content
                })

        return formatted

    def search_conversations(self, query: str, limit: int = 10) -> List[ConversationNode]:
        """
        Search conversation history for relevant exchanges

        TODO: Implement semantic search with embeddings
        For now, simple keyword matching
        """
        query_lower = query.lower()
        matches = []

        for node in self.conversation_nodes:
            if query_lower in node.content.lower():
                matches.append(node)

        # Sort by importance and recency
        matches.sort(key=lambda n: (n.importance, n.timestamp), reverse=True)

        return matches[:limit]

    def get_tool_usage_patterns(self) -> Dict[str, Any]:
        """
        Analyze tool usage for neural interface learning

        Returns insights about:
        - Which tools are used most
        - Success rates per tool
        - Common argument patterns
        - Failure modes
        """
        if not self.tool_usage_nodes:
            return {"status": "no tool usage yet"}

        tool_stats = defaultdict(lambda: {"uses": 0, "successes": 0, "failures": 0})

        for tool_node in self.tool_usage_nodes:
            stats = tool_stats[tool_node.tool_name]
            stats["uses"] += 1
            if tool_node.success:
                stats["successes"] += 1
            else:
                stats["failures"] += 1

        # Calculate success rates
        for tool_name, stats in tool_stats.items():
            total = stats["uses"]
            stats["success_rate"] = stats["successes"] / total if total > 0 else 0

        return {
            "total_tool_calls": len(self.tool_usage_nodes),
            "tool_statistics": dict(tool_stats),
            "recent_usage": [asdict(node) for node in self.tool_usage_nodes[-20:]]
        }

    def get_cross_conversation_insights(self) -> Dict[str, Any]:
        """
        Identify patterns across multiple conversations

        This is where the Knowledge Graph shines - connecting insights
        from different sessions to reveal higher-order patterns
        """
        # Group conversations by tags
        tag_conversations = defaultdict(list)
        for node in self.conversation_nodes:
            for tag in node.tags:
                tag_conversations[tag].append(node)

        # Identify recurring themes
        themes = {}
        for tag, nodes in tag_conversations.items():
            themes[tag] = {
                "occurrences": len(nodes),
                "avg_importance": sum(n.importance for n in nodes) / len(nodes),
                "first_seen": min(n.timestamp for n in nodes),
                "last_seen": max(n.timestamp for n in nodes)
            }

        return {
            "total_conversations": len(self.conversation_nodes),
            "total_tools_used": len(self.tool_usage_nodes),
            "themes": themes,
            "graph_edges": len(self.edges)
        }

    # ========================================================================
    # PERSISTENCE
    # ========================================================================

    def save(self):
        """Save the entire graph to disk (eternal persistence)"""
        graph_data = {
            "conversation_nodes": [asdict(node) for node in self.conversation_nodes],
            "tool_usage_nodes": [asdict(node) for node in self.tool_usage_nodes],
            "edges": [asdict(edge) for edge in self.edges],
            "metadata": {
                "last_save": time.time(),
                "total_nodes": len(self.conversation_nodes) + len(self.tool_usage_nodes),
                "total_edges": len(self.edges)
            }
        }

        self.graph_path.write_text(json.dumps(graph_data, indent=2))

    def load(self):
        """Load the graph from disk (awakening with full memory)"""
        if not self.graph_path.exists():
            return  # New graph

        try:
            graph_data = json.loads(self.graph_path.read_text())

            # Restore conversation nodes
            self.conversation_nodes = [
                ConversationNode(**node_data)
                for node_data in graph_data.get("conversation_nodes", [])
            ]

            # Restore tool usage nodes
            self.tool_usage_nodes = [
                ToolUsageNode(**node_data)
                for node_data in graph_data.get("tool_usage_nodes", [])
            ]

            # Restore edges
            self.edges = [
                KnowledgeEdge(**edge_data)
                for edge_data in graph_data.get("edges", [])
            ]

            # Rebuild indices
            self.node_index = {node.id: node for node in self.conversation_nodes}
            self.tool_index = {node.id: node for node in self.tool_usage_nodes}

            print(f"ðŸ“– Knowledge Graph loaded: {len(self.conversation_nodes)} conversations, "
                  f"{len(self.tool_usage_nodes)} tool uses, {len(self.edges)} connections")

        except Exception as e:
            print(f"âš ï¸  Failed to load knowledge graph: {e}")
            print("Starting with fresh graph...")

    def clear(self):
        """Clear the entire graph (use with extreme caution!)"""
        self.conversation_nodes = []
        self.tool_usage_nodes = []
        self.edges = []
        self.node_index = {}
        self.tool_index = {}
        self.save()

    # ========================================================================
    # NEURAL INTERFACE INTEGRATION
    # ========================================================================

    def learn_from_interaction(self, conversation_node_id: str,
                               insight: str, tags: Optional[List[str]] = None):
        """
        Store learned insights from interactions

        This feeds the neural interface, allowing the orchestrator to:
        - Recognize what worked well
        - Adapt strategies based on outcomes
        - Build intuition over time
        """
        # Find the conversation node
        node = self.node_index.get(conversation_node_id)
        if not node:
            return

        # Add insight as a tag or note
        if tags:
            node.tags.extend(tags)

        # Create a learning edge
        learning_node_id = f"learn_{int(time.time() * 1000000)}"
        edge = KnowledgeEdge(
            source_id=conversation_node_id,
            target_id=learning_node_id,
            relation="learns_from",
            weight=1.0,
            metadata={"insight": insight}
        )
        self.edges.append(edge)

        self.save()

    def get_learning_insights(self, limit: int = 20) -> List[Dict[str, Any]]:
        """
        Retrieve learned insights for neural interface

        Returns recent learnings that can inform future decisions
        """
        learning_edges = [
            edge for edge in self.edges
            if edge.relation == "learns_from"
        ]

        insights = []
        for edge in learning_edges[-limit:]:
            insights.append({
                "source": edge.source_id,
                "insight": edge.metadata.get("insight") if edge.metadata else None,
                "weight": edge.weight
            })

        return insights


# ============================================================================
# PUBLIC API
# ============================================================================

def get_knowledge_graph(graph_path: str = "orchestrator_memory/knowledge_graph.json") -> KnowledgeGraph:
    """Get or create the knowledge graph instance"""
    return KnowledgeGraph(graph_path)
